{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> BIT522 â€“ Machine Learning (Spring 2018)</center>\n",
    "# <center>Homework #4<center>\n",
    "\n",
    "# <center> Harlinton Palacios Mosquera</center>\n",
    "# <center>161041033</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harlinton\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import manifold, datasets, decomposition, discriminant_analysis\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Data</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X, y = make_moons(n_samples=100, random_state=123)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784) \n",
    "x_test = x_test.reshape(10000, 784)\n",
    "indices = np.random.permutation(np.arange(x_train.shape[0]))\n",
    "x_train = x_train[indices]\n",
    "y_train = y_train[indices]\n",
    "y_train\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <center>Part I: Implementing PCA</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 7.864s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from time import time\n",
    "from sklearn.decomposition import PCA\n",
    "n_components = 100\n",
    "t0 = time()\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
    "          whiten=True).fit(x_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "\n",
    "X_train_pca = pca.transform(x_train)\n",
    "X_test_pca = pca.transform(x_test)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Part II: Using PCA before Classification (k-means algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)  Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_centroids(data, clusters, k=None):\n",
    "\n",
    "    if k is None:\n",
    "        k = np.max(clusters) + 1\n",
    "    result = np.empty(shape=(k,) + data.shape[1:])\n",
    "    for i in range(k):\n",
    "        np.mean(data[clusters == i], axis=0, out=result[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.spatial\n",
    "\n",
    "def kmeans(data, k=None, centroids=None, steps=20):\n",
    " \n",
    "    if centroids is not None and k is not None:\n",
    "        assert(k == len(centroids))\n",
    "    elif centroids is not None:\n",
    "        k = len(centroids)\n",
    "    elif k is not None:\n",
    "        # Forgy initialization method: choose k data points randomly.\n",
    "        centroids = data[np.random.choice(np.arange(len(data)), k, False)]\n",
    "    else:\n",
    "        raise RuntimeError(\"Need a value for k or centroids.\")\n",
    "\n",
    "    for _ in range(max(steps, 1)):\n",
    "        \n",
    "        # Euclidean  distance between the points\n",
    "        \n",
    "        sqdists = scipy.spatial.distance.cdist(centroids, data, 'sqeuclidean')\n",
    "        \n",
    "        # Manhattan distance between the points\n",
    "        #sqdists = scipy.spatial.distance.cdist(centroids, data, 'cityblock')\n",
    "                \n",
    "        #Cosine distance between the points\n",
    "        #qdists = scipy.spatial.distance.cdist(centroids, data, 'cosine')\n",
    "\n",
    "\n",
    "         \n",
    "        # Index of the closest centroid to each data point.\n",
    "        clusters = np.argmin(sqdists, axis=0)\n",
    "\n",
    "        new_centroids = cluster_centroids(data, clusters, k)\n",
    "        if np.array_equal(new_centroids, centroids):\n",
    "            break\n",
    "\n",
    "        centroids = new_centroids\n",
    "    #print (centroids)\n",
    "    \n",
    "    return clusters , centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k= 10\n",
    "# cluster_label, centroids = kmeans(x_train,k)\n",
    "\n",
    "#cross validation\n",
    "from sklearn.model_selection import KFold\n",
    "k_fold= 5\n",
    "kf = KFold(n_splits = k_fold) # Define the split - into 5 folds \n",
    "kf.get_n_splits(X_train_pca) # returns the number of splitting iterations in the cross-validator\n",
    "\n",
    "centroids = None\n",
    "for train_index, test_index in kf.split(X_train_pca):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train_cv, X_test_cv = X_train_pca[train_index], X_train_pca[test_index]\n",
    "    cluster_label, centroids = kmeans(X_train_cv, k, centroids=centroids)\n",
    "\n",
    "cluster_label, centroids = kmeans(X_train_pca, k, centroids=centroids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = np.zeros((10, 10),dtype=np.int)\n",
    "\n",
    "for i, k  in enumerate(y_train):\n",
    "    c = cluster_label[i]\n",
    "    table[k,c] += 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 469    6    5  111 2511 2265  161   12  148  235]\n",
      " [ 519   14   36   44   47    0   18 6018   19   27]\n",
      " [ 429    6   88 1381 1073   54   53  201 1701  972]\n",
      " [ 244  262  101  252 4310    3   62  126  105  666]\n",
      " [1001  393 2351   12  365   13  608  302  179  618]\n",
      " [1352  213   84   75 1294   25 1648  107  126  497]\n",
      " [ 313    0    8 2187  106  342    9   72 2851   30]\n",
      " [   7 2806 1644    0  146   32  218 1287   44   81]\n",
      " [ 646  202  227   21 2935   44  789  393   57  537]\n",
      " [  15 2023 2449    0  214   23   52  643   22  508]]\n"
     ]
    }
   ],
   "source": [
    "print (table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dic = {}\n",
    "while len(dic) != 10:\n",
    "    index = table.argmax()\n",
    "    x = index // 10\n",
    "    y = index % 10\n",
    "    if y not in dic.keys() and x not in dic.values():\n",
    "        #print (table[x, y])\n",
    "        dic[y] = x\n",
    "    table[x, y] = -1\n",
    "#print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for y in cluster_label:\n",
    "    y_predict.append(dic[y])\n",
    "y_predict = np.array(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cluster_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "\n",
      " [[2265   12  111 2511  469  161  148    6  235    5]\n",
      " [   0 6018   44   47  519   18   19   14   27   36]\n",
      " [  54  201 1381 1073  429   53 1701    6  972   88]\n",
      " [   3  126  252 4310  244   62  105  262  666  101]\n",
      " [  13  302   12  365 1001  608  179  393  618 2351]\n",
      " [  25  107   75 1294 1352 1648  126  213  497   84]\n",
      " [ 342   72 2187  106  313    9 2851    0   30    8]\n",
      " [  32 1287    0  146    7  218   44 2806   81 1644]\n",
      " [  44  393   21 2935  646  789   57  202  537  227]\n",
      " [  23  643    0  214   15   52   22 2023  508 2449]]\n",
      "\n",
      "Accuracy:  42.11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "confuMatrix= confusion_matrix(y_train, y_predict)\n",
    "accuracy = accuracy_score(y_train, y_predict)*100\n",
    "\n",
    "print (\"Confusion Matrix: \\n\\n\" , confuMatrix)\n",
    "print (\"\\nAccuracy: \" , accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "\n",
      " [[ 370    1   20  453   59   14   28    3   32    0]\n",
      " [   0 1024    5   10   84    1    6    0    2    3]\n",
      " [  10   53  244  232   53    7  288    4  137    4]\n",
      " [   1   20   33  744   30    5   18   45   99   15]\n",
      " [   3   59    1   52  171   91   34   54   89  428]\n",
      " [   4   18    8  208  241  260   15   45   76   17]\n",
      " [  76    8  406   21   51    1  388    0    5    2]\n",
      " [   0  205    0   25    1   37   13  460   16  271]\n",
      " [   4   44    8  514  106  112    8   51   85   42]\n",
      " [   3   77    0   41    3    8    3  324   69  481]]\n",
      "\n",
      "Accuracy:  42.27\n"
     ]
    }
   ],
   "source": [
    "sqdists = scipy.spatial.distance.cdist(centroids, X_test_pca, 'sqeuclidean')\n",
    "y_test_predict = sqdists.argmin(axis=0)\n",
    "\n",
    "y_test_predict1 = []\n",
    "for y in y_test_predict:\n",
    "    y_test_predict1.append(dic[y])\n",
    "y_test_predict1\n",
    "\n",
    "ConfuMatrixnn = confusion_matrix(y_test, y_test_predict1)\n",
    "accuracynn =accuracy_score(y_test, y_test_predict1)*100\n",
    "\n",
    "print (\"Confusion Matrix: \\n\\n\" , ConfuMatrixnn)\n",
    "print (\"\\nAccuracy: \" , accuracynn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Results Of The Other Distance</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) L1 norm (Manhattan distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b>Labeling of clusters:</b> \n",
    "\n",
    "<img src=\"https://image.ibb.co/cDRRYJ/Table1.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "<b>Training error :</b> \n",
    "<img src=\"https://image.ibb.co/nqqmYJ/resul1.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "<b>Test error with 1-NN:</b> \n",
    "<img src=\"https://image.ibb.co/dyCdfy/MatriNN.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Cosine distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Labeling of clusters:</b> \n",
    "\n",
    "<img src=\"https://image.ibb.co/m6ybHd/Cosine_Table.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "<b>Training error :</b> \n",
    "<img src=\"https://image.ibb.co/kBAZ3J/matris1cosine.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "<b>Test error with 1-NN:</b> \n",
    "<img src=\"https://image.ibb.co/eeC3xd/Matrixconcine_NN.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K means is a heuristic algorithm that partitions a data set into \n",
    "K clusters by minimizing the sum of squared distance in each \n",
    "cluster.  During  the  implementation  of  k\n",
    "-\n",
    "means  with  three \n",
    "different  d\n",
    "istance  metrics,  it  is  observed  that  selection  of \n",
    "distance  metric  plays  a  very  important  role  in  clustering.  So, \n",
    "the selection of distance metric should be made carefully. The \n",
    "distortion  in  k\n",
    "-\n",
    "means  using  Cosine distance  metric  is  less \n",
    "than that of k\n",
    "-\n",
    "mea\n",
    "ns using Euclidean and Manhattan distance metric.\n",
    "As  a  conclusion,  the  K\n",
    "-\n",
    "means,  which  is  implemented  using \n",
    "Euclidean  distance  metric  gives  best  result  and  K\n",
    "-\n",
    "means \n",
    "based on Cosine distance metricâ€™s performance, is worst."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
